{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sesi√≥n 3: Procesamiento Avanzado de Im√°genes** ‚öôÔ∏èüñºÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "from typing import List\n",
    "import glob\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apartado A: Detecci√≥n de esquinas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este apartado es detectar las esquinas presentes en las im√°genes de la carpeta ``data/source``.\n",
    "\n",
    "1. **Tarea A.1**. Cree una nueva capeta llamada ``partA``, dentro de la carpeta  ``data``, con el objetivo de presentar en ella los resultados de esta parte de la pr√°ctica.\n",
    "2. **Tarea A.2**. Defina y ejecute los dos m√©todos propuestos para cargar im√°genes ``imageio_load_images()`` y ``opencv_load_images()``. Observe lo que ocurre al guardar ambas im√°genes usando la misma funci√≥n ``cv2.imwrite()``.\n",
    "3. **Tarea A.3.** Defina la funci√≥n ``harris_corner_detector()``, que servir√° para la posterior aplicaci√≥n sobre las im√°genes de trabajo. \n",
    "4. **Tarea A.4.** Aplique la funci√≥n ``harris_corner_detector()`` sobre las im√°genes de trabajo. Aseg√∫rese de que las im√°genes quedan guardadas como se especifica en los comentarios.\n",
    "5. **Tarea A.5.** Defina la funci√≥n ``shi_tomasi_corner_detection()``, que servir√° para la posterior aplicaci√≥n sobre las im√°genes de trabajo.\n",
    "6. **Tarea A.6.** Aplique la funci√≥n ``shi_tomasi_corner_detection()`` sobre las im√°genes de trabajo. Aseg√∫rese de que las im√°genes quedan guardadas como se especifica en los comentarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.1**. Cree una nueva capeta llamada ``partA``, dentro de la carpeta  ``data``, con el objetivo de presentar en ella los resultados de esta parte de la pr√°ctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO Create a folder to save all partA results (inside data)\n",
    "import os\n",
    "\n",
    "folder_name = \"partA\"\n",
    "folder_path = os.path.join(\"../data\", folder_name)\n",
    "os.makedirs(folder_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.2**. Defina y ejecute los dos m√©todos propuestos para cargar im√°genes ``imageio_load_images()`` y ``opencv_load_images()``. Observe lo que ocurre al guardar ambas im√°genes usando la misma funci√≥n ``cv2.imwrite()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This initial part is to highlight that cv2.imshow() and cv2.imwrite() works well with previous BGR conversion\n",
    "def imageio_load_images(filenames: List[str]) -> List:\n",
    "    '''\n",
    "    Load images using imageio.imread function (RGB)\n",
    "    '''\n",
    "    return [imageio.v2.imread(filename) for filename in filenames]\n",
    "\n",
    "def opencv_load_images(filenames: List) -> List:\n",
    "    '''\n",
    "    Load images cv2.imread function (BGR)\n",
    "    '''\n",
    "    return [cv2.imread(filename) for filename in filenames]\n",
    "\n",
    "# TODO Create two sorted lists with the paths of all images in the data/source folder using glob\n",
    "source_folder = os.path.join(\"../data\", \"source\")\n",
    "source_paths = sorted(glob.glob(os.path.join(source_folder, \"*\")))  # Cambia \"*.jpg\" por la extensi√≥n correcta si es diferente\n",
    "imageio_images = imageio_load_images(source_paths)\n",
    "opencv_images = opencv_load_images(source_paths)\n",
    "\n",
    "print(len(imageio_images))\n",
    "\n",
    "destination_folder = \"../data/partA\"\n",
    "\n",
    "cv2.imwrite(os.path.join(destination_folder, \"imageio_blue_court.jpg\"), imageio_images[3])\n",
    "cv2.imwrite(os.path.join(destination_folder, \"opencv_blue_court.jpg\"), opencv_images[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.3.** Defina la funci√≥n ``harris_corner_detector()``, que servir√° para la posterior aplicaci√≥n sobre las im√°genes de trabajo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define Harris Corner detection function\n",
    "def harris_corner_detector(image: np.array, blockSize: int, ksize: int, k: float):\n",
    "    '''\n",
    "    image - Input image \n",
    "    blockSize - Size of neighborhood considered for corner detection\n",
    "    ksize - Aperture parameter of the Sobel derivative used\n",
    "    k - Harris detector free parameter in the equation.\n",
    "    '''\n",
    "    # TODO Input image to Harris corner detector should be grayscale \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # TODO Input image to Harris corner detector should be float32 type\n",
    "    gray = np.float32(gray)\n",
    "    # TODO Apply Harris corner detection\n",
    "    harris = cv2.cornerHarris(src=gray, blockSize=blockSize, ksize=ksize, k=k)\n",
    "    # Result is dilated for marking the corners, not important\n",
    "    harris = cv2.dilate(harris, None)\n",
    "    # TODO Threshold for an optimal value of 1% of maximal R value\n",
    "    # If pixel value > 1% max value, yo should to hightlight this as a red corner\n",
    "    threshold = 0.01 * harris.max()\n",
    "    image[harris > threshold] = [0, 0, 255]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.4.** Aplique la funci√≥n ``harris_corner_detector()`` sobre las im√°genes de trabajo. Aseg√∫rese de que las im√°genes quedan guardadas como se especifica en los comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This section is designed to to change corner detection parameters for each image\n",
    "# We want to save processed image in path: Lab3/data/partA/Harris_{save_name}.jpg\n",
    "\n",
    "# First image\n",
    "save_name = \"geometry\"\n",
    "# TODO Copy first original image\n",
    "image = cv2.imread(\"../data/source/0.jpg\")\n",
    "# TODO Apply Harris Corner Detection\n",
    "harris_image = harris_corner_detector(image, blockSize=2, ksize=3, k=0.04)\n",
    "# TODO Save final image in partA folder\n",
    "cv2.imwrite(os.path.join(\"../data/oartA\", f\"Harris_{save_name}.jpg\"), harris_image)\n",
    "\n",
    "# Second image\n",
    "save_name = \"football\"\n",
    "# TODO Copy second original image\n",
    "image = cv2.imread(\"../data/source/1.png\")\n",
    "# TODO Apply Harris Corner Detection\n",
    "harris_image = harris_corner_detector(image, blockSize=2, ksize=3, k=0.04)\n",
    "cv2.imwrite(os.path.join(destination_folder, f\"Harris_{save_name}.jpg\"), harris_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.5.** Defina la funci√≥n ``shi_tomasi_corner_detection()``, que servir√° para la posterior aplicaci√≥n sobre las im√°genes de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO Define Shi-Tomasi corner detection function\n",
    "def shi_tomasi_corner_detection(image: np.array, maxCorners: int, qualityLevel:float, minDistance: int, corner_color: tuple, radius: int):\n",
    "    '''\n",
    "    image - Input image\n",
    "    maxCorners - Maximum number of corners to return. \n",
    "                 If there are more corners than are found, the strongest of them is returned. \n",
    "                 maxCorners <= 0 implies that no limit on the maximum is set and all detected corners are returned\n",
    "    qualityLevel - Parameter characterizing the minimal accepted quality of image corners. \n",
    "                   The parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue or the Harris function response. \n",
    "                   The corners with the quality measure less than the product are rejected. \n",
    "                   For example, if the best corner has the quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure less than 15 are rejected\n",
    "    minDistance - Minimum possible Euclidean distance between the returned corners\n",
    "    corner_color - Desired color to highlight corners in the original image\n",
    "    radius - Desired radius (pixels) of the circle\n",
    "    '''\n",
    "    # TODO Input image to Tomasi corner detector should be grayscale \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # TODO Apply cv2.goodFeaturesToTrack function\n",
    "    corners = cv2.goodFeaturesToTrack(gray, maxCorners=maxCorners, qualityLevel=qualityLevel, minDistance=minDistance)\n",
    "    # TODO Corner coordinates conversion to integers\n",
    "    corners = np.intp(corners) if corners is not None else []\n",
    "    for corner in corners:\n",
    "        # Multidimensional array into flattened array, if necessary\n",
    "        x, y = corner.ravel()\n",
    "        # TODO Circle corners\n",
    "        cv2.circle(image, (x, y), radius, corner_color, 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.6.** Aplique la funci√≥n ``shi_tomasi_corner_detection()`` sobre las im√°genes de trabajo. Aseg√∫rese de que las im√°genes quedan guardadas como se especifica en los comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This section is designed to to change corner detection parameters for each image\n",
    "# We want to save processed image in path: Lab3/data/partA/Shi-Tomasi_{save_name}.jpg\n",
    "\n",
    "# First image - Purple corners and radius = 4\n",
    "save_name = \"geometry\"\n",
    "# TODO Purple color in adequate color space\n",
    "purple_color = (255, 0, 255)\n",
    "# TODO Copy first original image\n",
    "image = cv2.imread(\"../data/source/0.jpg\")\n",
    "# TODO Apply Shi-Tomasi corner detection\n",
    "tomasi_image = shi_tomasi_corner_detection(image, maxCorners=50, qualityLevel=0.1, minDistance=10, corner_color=purple_color, radius=4)\n",
    "\n",
    "# TODO Save final image in partA folder\n",
    "cv2.imwrite(os.path.join(destination_folder, f\"ShiTomasi_{save_name}.jpg\"), tomasi_image)\n",
    "\n",
    "# Second image - Orange corners and radius = 4\n",
    "save_name = \"football\"\n",
    "# TODO Orange color in adequate color space\n",
    "orange_color = (0, 165, 255) \n",
    "# TODO Copy second original image\n",
    "image = cv2.imread(\"../data/source/1.png\")\n",
    "tomasi_image = shi_tomasi_corner_detection(image, maxCorners=42, qualityLevel=0.1, minDistance=10, corner_color=orange_color, radius=4)\n",
    "# TODO Save final image in partA folder\n",
    "cv2.imwrite(os.path.join(destination_folder, f\"ShiTomasi_{save_name}.jpg\"), tomasi_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.1:** Realice la detecci√≥n de esquinas en las otras dos im√°genes de la carpeta ``data/source`` (cuyos nombres de guardado han de ser \"sudoku\" y \"tennis\") con el m√©todo de Harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code by yourself\n",
    "# Code by yourself\n",
    "\n",
    "# Crear la carpeta de salida si no existe\n",
    "output_dir = \"../data/partA\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Tercera imagen - Sudoku\n",
    "save_name = \"sudoku\"\n",
    "# Copiar la tercera imagen original (indice 2 para \"sudoku\")\n",
    "image = copy.copy(opencv_images[2])\n",
    "# Aplicar la detecci√≥n de esquinas de Harris\n",
    "harris_image = harris_corner_detector(image, blockSize=2, ksize=3, k=0.04)\n",
    "# Guardar la imagen procesada\n",
    "cv2.imwrite(f\"{output_dir}/{save_name}.jpg\", harris_image)\n",
    "\n",
    "# Cuarta imagen - Tennis\n",
    "save_name = \"tennis\"\n",
    "# Copiar la cuarta imagen original (indice 3 para \"tennis\")\n",
    "image = copy.copy(opencv_images[3])\n",
    "# Aplicar la detecci√≥n de esquinas de Harris\n",
    "harris_image = harris_corner_detector(image, blockSize=2, ksize=3, k=0.04)\n",
    "# Guardar la imagen procesada\n",
    "cv2.imwrite(f\"{output_dir}/{save_name}.jpg\", harris_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.2:** Realice la detecci√≥n de esquinas en las otras dos im√°genes de la carpeta ``data/source`` (cuyos nombres de guardado han de ser \"sudoku\" y \"tennis\") con el m√©todo de Shi-Tomasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code by yourself\n",
    "# Code by yourself\n",
    "# Tercera imagen - Sudoku, con esquinas en azul y radio = 4\n",
    "save_name = \"sudoku\"\n",
    "blue_color = (255, 0, 0)  # Color azul en el espacio de color BGR\n",
    "# Copiar la tercera imagen original\n",
    "image = copy.copy(opencv_images[2])\n",
    "# Aplicar la detecci√≥n de esquinas de Shi-Tomasi\n",
    "tomasi_image = shi_tomasi_corner_detection(\n",
    "    image, maxCorners=50, qualityLevel=0.02, minDistance=55, \n",
    "    corner_color=blue_color, radius=4\n",
    ")\n",
    "# Guardar la imagen procesada\n",
    "cv2.imwrite(f\"{output_dir}/tomasi_image_{save_name}.jpg\", tomasi_image)\n",
    "\n",
    "# Cuarta imagen - Tennis, con esquinas en amarillo y radio = 4\n",
    "save_name = \"tennis\"\n",
    "yellow_color = (0, 255, 255)  # Color amarillo en el espacio de color BGR\n",
    "# Copiar la cuarta imagen original\n",
    "image = copy.copy(opencv_images[3])\n",
    "# Aplicar la detecci√≥n de esquinas de Shi-Tomasi\n",
    "tomasi_image = shi_tomasi_corner_detection(\n",
    "    image, maxCorners=45, qualityLevel=0.02, minDistance=10, \n",
    "    corner_color=yellow_color, radius=4\n",
    ")\n",
    "# Guardar la imagen procesada\n",
    "cv2.imwrite(f\"{output_dir}/tomasi_image_{save_name}.jpg\", tomasi_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
